import os
from dotenv import load_dotenv
from langchain.memory import ConversationBufferMemory
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough, RunnableSequence
from pydantic import BaseModel

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# âœ… LangChain Gemini ëª¨ë¸ ì„¤ì •
llm_ai1 = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=GEMINI_API_KEY, request_timeout=60)
llm_ai2 = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=GEMINI_API_KEY, request_timeout=60)
llm_moderator = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=GEMINI_API_KEY, request_timeout=60)
llm_judge = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=GEMINI_API_KEY, request_timeout=60)

# âœ… í† ë¡  ë©”ëª¨ë¦¬
class DebateMemory(ConversationBufferMemory, BaseModel):
    class Config:
        extra = "allow"

    def __init__(self, speaker_role: str, **kwargs):
        super().__init__(**kwargs)
        self.speaker_role = speaker_role

    def save_context(self, inputs, outputs):
        """ë°œì–¸ìì˜ ë°œì–¸ì„ ë©”ëª¨ë¦¬ì— ì €ì¥"""
        input_message = {"speaker": inputs["speaker"], "content": inputs["input"]}
        output_message = {"speaker": inputs["speaker"], "content": outputs["output"]}
        self.chat_memory.add_user_message(input_message["content"])
        self.chat_memory.add_ai_message(output_message["content"])

    def load_memory_variables(self, inputs):
        """íŠ¹ì • ë°œì–¸ìì˜ ë©”ì‹œì§€ë§Œ ë¶ˆëŸ¬ì˜¤ê¸°"""
        return {
            "history": [
                msg for msg in self.chat_memory.messages
                if isinstance(msg, dict) and msg.get("speaker") == inputs.get("speaker")
            ]
        }

# âœ… AI1, AI2 ë©”ëª¨ë¦¬ ìƒì„±
ai1_memory = DebateMemory(speaker_role="AI1")
ai2_memory = DebateMemory(speaker_role="AI2")

# âœ… ì´ˆê¸° ì£¼ì¥
ai1_original_claim = "ë‹­ì´ ë‹¬ê±€ë³´ë‹¤ ë¨¼ì €ë‹¤. ìƒë¬¼í•™ì , ì² í•™ì  ê´€ì ì—ì„œ ì´ëŠ” ì‚¬ì‹¤ì´ë‹¤."
ai2_original_claim = "ë‹¬ê±€ì´ ë‹­ë³´ë‹¤ ë¨¼ì €ë‹¤. ì§„í™”ë¡ ì  ì¦ê±°ê°€ ì´ë¥¼ ë’·ë°›ì¹¨í•œë‹¤."

# âœ… Memoryì— ì´ˆê¸° ì£¼ì¥ ì €ì¥
ai1_memory.save_context({"speaker": "AI1", "input": ai1_original_claim}, {"output": ai1_original_claim})
ai2_memory.save_context({"speaker": "AI2", "input": ai2_original_claim}, {"output": ai2_original_claim})

# âœ… ì—­í•  ì‹œìŠ¤í…œ ë©”ì‹œì§€ (RunnableLambda ì‚¬ìš©)
ai1_system_message = RunnableLambda(lambda _: SystemMessage(content="ë‹¹ì‹ ì€ ë‹­ì´ ë¨¼ì €ë¼ê³  ì£¼ì¥í•˜ëŠ” í† ë¡ ìì…ë‹ˆë‹¤. ë…¼ë¦¬ë¥¼ ìœ ì§€í•˜ë©° ìƒëŒ€ë°©ì˜ ë°˜ë°•ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ë°˜ê²©í•˜ì„¸ìš”."))
ai2_system_message = RunnableLambda(lambda _: SystemMessage(content="ë‹¹ì‹ ì€ ë‹¬ê±€ì´ ë¨¼ì €ë¼ê³  ì£¼ì¥í•˜ëŠ” í† ë¡ ìì…ë‹ˆë‹¤. ë…¼ë¦¬ë¥¼ ìœ ì§€í•˜ë©° ìƒëŒ€ë°©ì˜ ë°˜ë°•ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ë°˜ê²©í•˜ì„¸ìš”."))

# âœ… AI1ê³¼ AI2 ì²´ì¸ìš© í”„ë¡¬í”„íŠ¸
ai1_claim_prompt = PromptTemplate(
    input_variables=["previous"],
    template="ë‹¹ì‹ (AI1)ì˜ ì£¼ì¥ì€: {previous} \nì´ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì „ê°œí•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”."
)

ai2_claim_prompt = PromptTemplate(
    input_variables=["previous"],
    template="ë‹¹ì‹ (AI2)ì˜ ì£¼ì¥ì€: {previous} \nì´ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì „ê°œí•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”."
)

ai1_rebuttal_prompt = PromptTemplate(
    input_variables=["previous", "opponent"],
    template="ë‹¹ì‹ (AI1)ì˜ ì£¼ì¥ì€: {previous} \nìƒëŒ€ë°©(AI2)ì˜ ì£¼ì¥: {opponent}\nì´ì— ëŒ€í•´ ë°˜ë“œì‹œ ë°˜ë°•í•˜ë©°, ìƒëŒ€ë°© ì£¼ì¥ì˜ ì•½ì ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì§€ì í•˜ì„¸ìš”."
)

ai2_rebuttal_prompt = PromptTemplate(
    input_variables=["previous", "opponent"],
    template="ë‹¹ì‹ (AI2)ì˜ ì£¼ì¥ì€: {previous} \nìƒëŒ€ë°©(AI1)ì˜ ì£¼ì¥: {opponent}\nì´ì— ëŒ€í•´ ë°˜ë“œì‹œ ë°˜ë°•í•˜ë©°, ìƒëŒ€ë°© ì£¼ì¥ì˜ ì•½ì ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì§€ì í•˜ì„¸ìš”."
)

# âœ… ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜ (RunnableLambda í™œìš©)
def print_response(label, response):
    """í† ë¡  ì§„í–‰ ê³¼ì •ì˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    content = response.content if isinstance(response, AIMessage) else response
    print(f"\n=== {label} ===\n{content}")
    return response

print_ai1_claim = RunnableLambda(lambda x: print_response("ğŸŸ¢ AI1 ë…¼ë¦¬ ì „ê°œ", x))
print_ai2_claim = RunnableLambda(lambda x: print_response("ğŸ”µ AI2 ë…¼ë¦¬ ì „ê°œ", x))
print_ai1_rebuttal = RunnableLambda(lambda x: print_response("ğŸŸ¢ AI1 ë°˜ë°•", x))
print_ai2_rebuttal = RunnableLambda(lambda x: print_response("ğŸ”µ AI2 ë°˜ë°•", x))

# âœ… AI1ê³¼ AI2 ì²´ì¸ ìƒì„± (RunnableSequenceë¡œ êµ¬ì„±)
ai1_claim_chain = RunnableSequence(
    RunnablePassthrough(),
    ai1_system_message,
    ai1_claim_prompt,
    llm_ai1,
    print_ai1_claim
)

ai2_claim_chain = RunnableSequence(
    RunnablePassthrough(),
    ai2_system_message,
    ai2_claim_prompt,
    llm_ai2,
    print_ai2_claim
)

ai1_rebuttal_chain = RunnableSequence(
    RunnablePassthrough(),
    ai1_rebuttal_prompt,
    llm_ai1,
    print_ai1_rebuttal
)

ai2_rebuttal_chain = RunnableSequence(
    RunnablePassthrough(),
    ai2_rebuttal_prompt,
    llm_ai2,
    print_ai2_rebuttal
)

# âœ… Moderator Agent (í† ë¡  ì§„í–‰)
def moderate_debate(_):
    print("\n=== í† ë¡  ì‹œì‘ ===")

    ai1_claim = ai1_claim_chain.invoke({"previous": ai1_original_claim})
    ai2_claim = ai2_claim_chain.invoke({"previous": ai2_original_claim})

    ai1_rebuttal = ai1_rebuttal_chain.invoke({"previous": ai1_claim.content, "opponent": ai2_claim.content})
    ai2_rebuttal = ai2_rebuttal_chain.invoke({"previous": ai2_claim.content, "opponent": ai1_claim.content})

    return {
        "ai1_claim": ai1_claim.content,
        "ai2_claim": ai2_claim.content,
        "ai1_rebuttal": ai1_rebuttal.content,
        "ai2_rebuttal": ai2_rebuttal.content,
    }

moderator_chain = RunnableLambda(moderate_debate)

# âœ… Judge Agent (í† ë¡  í‰ê°€)
judge_prompt = PromptTemplate(
    input_variables=["ai1_claim", "ai2_claim", "ai1_rebuttal", "ai2_rebuttal"],
    template=(
        "ë‹¹ì‹ ì€ AI í† ë¡ ì˜ ì‹¬íŒì…ë‹ˆë‹¤.\n"
        "ì£¼ì œ: ë‹­ì´ ë¨¼ì €ì¸ê°€, ë‹¬ê±€ì´ ë¨¼ì €ì¸ê°€?\n\n"
        "AI1 ì£¼ì¥: {ai1_claim}\n"
        "AI2 ì£¼ì¥: {ai2_claim}\n\n"
        "AI1 ë°˜ë°•: {ai1_rebuttal}\n"
        "AI2 ë°˜ë°•: {ai2_rebuttal}\n\n"
        "ì–´ëŠ ì£¼ì¥ì´ ë” ë…¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹í•œì§€ í‰ê°€í•˜ì„¸ìš”."
    )
)

judge_chain = judge_prompt | llm_judge

# âœ… í† ë¡  ì§„í–‰
moderated_result = moderator_chain.invoke({})
print("\n=== ìµœì¢… í‰ê°€ ===")
debate_result = judge_chain.invoke(moderated_result)
print(debate_result.content)
