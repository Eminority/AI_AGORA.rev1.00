generate_text_config:
  debate:
    max_tokens: 1000
    k: 3
    temperature: 0.7


VectorStoreHandler:
  chunk_size: 500
  chunk_overlap: 50

ai:
  gemini:
    - "GEMINI"
  groq:
    - "deepseek-r1-distill-llama-70b"
    - "deepseek-r1-distill-qwen-32b"
    - "gemma2-9b-it"
    - "llama-3.1-8b-instant"
    - "llama-3.2-1b-preview"
    - "llama-3.2-3b-preview"
    - "llama-3.3-70b-specdec"
    - "llama-3.3-70b-versatile"
    - "llama3-70b-8192"
    - "llama3-8b-8192"
    - "mixtral-8x7b-32768"
    - "qwen-2.5-32b"
    - "qwen-2.5-coder-32b"
  ollama:
    - "phi3:mini"
    - "llama3.2"
    - "deepseek-r1:7b"
    - "exaone3.5:7.8b"
    - "exaone3.5"
    - "mistral"
    - "llama3"